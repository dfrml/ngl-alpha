<!DOCTYPE html>
<html lang="en">

<head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
  <script src="utils.js"></script>
  <script src="opencv3_4.js" type="text/javascript"></script>
  <!-- <script src="https://docs.opencv.org/master/opencv.js" type="text/javascript"></script> -->
  <script src="https://kit.fontawesome.com/b7835224ad.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="style.css">
  <title></title>
</head>

<body>
  <div class="top">
    <h1>NGL-measure</h1>
    <p>alpha 0.5 210301 _ Measure subjective state using camera. This demo recognizes three states {high/medium/low}
      based on your facial characteristics.
      Your data is used for algorithm improvements.</p>
  </div>

  <video id="video" autoplay playsinline muted></video>
  <canvas id="imageUploaded" class="none"></canvas>
  <!-- heartbeat.js stuff -->
  <video hidden id="webcam" width="640" height="480"></video>
  <canvas id="canvas" class="video" style="z-index: 1;"></canvas>

  <div class="bottom">
    <canvas id="imageCropped" class="imagePreview"></canvas>
    <canvas id="imageFaceDetected" class="imagePreview"></canvas>
    <canvas id="imageCaptured" width="640 " height="480" style="display: none;"></canvas>
    <div>
      <h2 id="result"></h2>
      <p id="resultJSON" style="font-size: 0.6em;"></p>
    </div>
    <div>
      <button id="snap">Snap Photo</button>
      <div id="upload" class="fakeInput"><button>From File</button><input type="file" id="imageInput"
          accept="image/*" /></div>
    </div>
  </div>
  <script src="affect.js"></script>
  <script src="heartbeat.js"></script>
</body>

</html>